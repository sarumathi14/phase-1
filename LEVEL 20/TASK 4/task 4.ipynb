{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d6dcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\sarum\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sarum\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.13.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\sarum\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sarum\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarum\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarum\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarum\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sarum\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sarum\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4) (4.13.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\sarum\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sarum\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sarum\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sarum\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sarum\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\sarum\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d78e1161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting IPL Match Data ETL Pipeline...\n",
      "Extracting match data from Cricbuzz...\n",
      "Found 74 matches\n",
      "Transforming data...\n",
      "Loading data to CSV...\n",
      "Data successfully saved to ipl_matches.csv\n",
      "ETL Pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_ipl_match_data():\n",
    "    \"\"\"\n",
    "    Extract IPL match data from Cricbuzz\n",
    "    Returns a list of dictionaries containing match information\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.cricbuzz.com/cricket-series/7607/indian-premier-league-2024/matches\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(base_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        match_cards = soup.find_all('div', class_='cb-col-75 cb-col')\n",
    "        matches = []\n",
    "        \n",
    "        for card in match_cards:\n",
    "            match_info = {}\n",
    "            \n",
    "            # Extract match title and link\n",
    "            title_tag = card.find('a', class_='text-hvr-underline')\n",
    "            if title_tag:\n",
    "                match_info['title'] = title_tag.text.strip()\n",
    "                match_info['match_url'] = \"https://www.cricbuzz.com\" + title_tag['href']\n",
    "            \n",
    "            # Extract match number and series\n",
    "            series_info = card.find('div', class_='text-gray')\n",
    "            if series_info:\n",
    "                match_info['series_info'] = series_info.text.strip()\n",
    "            \n",
    "            # Extract match location and time\n",
    "            location_time = card.find('div', class_='text-gray cb-font-12')\n",
    "            if location_time:\n",
    "                parts = [part.strip() for part in location_time.text.split('â€¢') if part.strip()]\n",
    "                if len(parts) >= 2:\n",
    "                    match_info['venue'] = parts[0]\n",
    "                    match_info['date_time'] = parts[1]\n",
    "            \n",
    "            # Extract match result if available\n",
    "            result_tag = card.find('div', class_='cb-scr-wll-chvrn cb-lv-scrs-col')\n",
    "            if result_tag:\n",
    "                match_info['result'] = result_tag.text.strip()\n",
    "            \n",
    "            if match_info:\n",
    "                matches.append(match_info)\n",
    "                \n",
    "        return matches\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return []\n",
    "\n",
    "def transform_match_data(matches):\n",
    "    \"\"\"\n",
    "    Transform raw match data into a structured format\n",
    "    \"\"\"\n",
    "    transformed = []\n",
    "    \n",
    "    for match in matches:\n",
    "        # Parse date and time\n",
    "        date_str = match.get('date_time', '')\n",
    "        try:\n",
    "            match_date = datetime.strptime(date_str, '%b %d, %Y, %I:%M %p')\n",
    "            formatted_date = match_date.strftime('%Y-%m-%d')\n",
    "            formatted_time = match_date.strftime('%H:%M')\n",
    "        except ValueError:\n",
    "            formatted_date = date_str\n",
    "            formatted_time = ''\n",
    "        \n",
    "        # Extract teams from title\n",
    "        teams = []\n",
    "        title = match.get('title', '')\n",
    "        if 'vs' in title:\n",
    "            teams = [team.strip() for team in title.split('vs')]\n",
    "        \n",
    "        # Create transformed record\n",
    "        record = {\n",
    "            'match_title': title,\n",
    "            'team1': teams[0] if len(teams) > 0 else '',\n",
    "            'team2': teams[1] if len(teams) > 1 else '',\n",
    "            'series': match.get('series_info', ''),\n",
    "            'venue': match.get('venue', ''),\n",
    "            'date': formatted_date,\n",
    "            'time': formatted_time,\n",
    "            'result': match.get('result', 'Upcoming'),\n",
    "            'match_url': match.get('match_url', '')\n",
    "        }\n",
    "        transformed.append(record)\n",
    "    \n",
    "    return transformed\n",
    "\n",
    "def load_to_csv(data, filename='ipl_matches.csv'):\n",
    "    \"\"\"\n",
    "    Load transformed data to CSV file\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Data successfully saved to {filename}\")\n",
    "\n",
    "def main():\n",
    "    print(\"Starting IPL Match Data ETL Pipeline...\")\n",
    "    \n",
    "    # Extract data\n",
    "    print(\"Extracting match data from Cricbuzz...\")\n",
    "    raw_matches = extract_ipl_match_data()\n",
    "    print(f\"Found {len(raw_matches)} matches\")\n",
    "    \n",
    "    # Transform data\n",
    "    print(\"Transforming data...\")\n",
    "    transformed_data = transform_match_data(raw_matches)\n",
    "    \n",
    "    # Load data\n",
    "    print(\"Loading data to CSV...\")\n",
    "    load_to_csv(transformed_data)\n",
    "    \n",
    "    print(\"ETL Pipeline completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
