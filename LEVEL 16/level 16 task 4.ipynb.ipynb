{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcd0a6a9-09e5-4182-802d-de854cfbd0c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Number of unique teams:\nTotal unique teams: 4\n\n2. Different tie-breaker techniques used for tied matches:\nTie-breaker methods:\n- super over\n- boundary count\n- bowl-out\n\n3. Filtering only completed matches:\nTotal matches: 7\nCompleted matches: 6\n\n4. Dropping unnecessary columns:\nFinal DataFrame schema:\nroot\n |-- match_id: integer (nullable = true)\n |-- team1: string (nullable = true)\n |-- team2: string (nullable = true)\n |-- winner: string (nullable = true)\n |-- result: string (nullable = true)\n |-- tie_breaker: string (nullable = true)\n\n\nSample data from final DataFrame:\n+--------+------+------+------+------+--------------+\n|match_id| team1| team2|winner|result|   tie_breaker|\n+--------+------+------+------+------+--------------+\n|       1|Team A|Team B|Team A|normal|          NULL|\n|       2|Team C|Team D|  NULL|   tie|    super over|\n|       3|Team A|Team C|Team C|normal|          NULL|\n|       4|Team B|Team D|  NULL|   tie|boundary count|\n|       6|Team B|Team C|Team B|normal|          NULL|\n|       7|Team C|Team D|  NULL|   tie|      bowl-out|\n+--------+------+------+------+------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, countDistinct\n",
    "from pyspark.sql.types import *\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "match_schema = StructType([\n",
    "    StructField(\"match_id\", IntegerType()),\n",
    "    StructField(\"team1\", StringType()),\n",
    "    StructField(\"team2\", StringType()),\n",
    "    StructField(\"winner\", StringType()),\n",
    "    StructField(\"result\", StringType()),\n",
    "    StructField(\"tie_breaker\", StringType()),\n",
    "    StructField(\"match_status\", StringType()),\n",
    "    StructField(\"venue\", StringType()),\n",
    "    StructField(\"umpire\", StringType())\n",
    "])\n",
    "match_data = [\n",
    "    (1, \"Team A\", \"Team B\", \"Team A\", \"normal\", None, \"completed\", \"Stadium X\", \"Umpire 1\"),\n",
    "    (2, \"Team C\", \"Team D\", None, \"tie\", \"super over\", \"completed\", \"Stadium Y\", \"Umpire 2\"),\n",
    "    (3, \"Team A\", \"Team C\", \"Team C\", \"normal\", None, \"completed\", \"Stadium Z\", \"Umpire 3\"),\n",
    "    (4, \"Team B\", \"Team D\", None, \"tie\", \"boundary count\", \"completed\", \"Stadium X\", \"Umpire 1\"),\n",
    "    (5, \"Team A\", \"Team D\", None, None, None, \"abandoned\", \"Stadium Y\", \"Umpire 2\"),\n",
    "    (6, \"Team B\", \"Team C\", \"Team B\", \"normal\", None, \"completed\", \"Stadium Z\", \"Umpire 3\"),\n",
    "    (7, \"Team C\", \"Team D\", None, \"tie\", \"bowl-out\", \"completed\", \"Stadium X\", \"Umpire 1\")\n",
    "]\n",
    "matches_df = spark.createDataFrame(match_data, schema=match_schema)\n",
    "print(\"1. Number of unique teams:\")\n",
    "teams_df = matches_df.select(col(\"team1\")).union(matches_df.select(col(\"team2\")))\n",
    "unique_teams_count = teams_df.agg(countDistinct(\"team1\")).collect()[0][0]\n",
    "print(f\"Total unique teams: {unique_teams_count}\\n\")\n",
    "print(\"2. Different tie-breaker techniques used for tied matches:\")\n",
    "tie_breakers = matches_df.filter(col(\"result\") == \"tie\") \\\n",
    "                         .select(\"tie_breaker\") \\\n",
    "                         .distinct() \\\n",
    "                         .collect()\n",
    "print(\"Tie-breaker methods:\")\n",
    "for row in tie_breakers:\n",
    "    print(f\"- {row['tie_breaker']}\")\n",
    "print()\n",
    "print(\"3. Filtering only completed matches:\")\n",
    "completed_matches = matches_df.filter(col(\"match_status\") == \"completed\")\n",
    "print(f\"Total matches: {matches_df.count()}\")\n",
    "print(f\"Completed matches: {completed_matches.count()}\\n\")\n",
    "print(\"4. Dropping unnecessary columns:\")\n",
    "columns_to_keep = [\"match_id\", \"team1\", \"team2\", \"winner\", \"result\", \"tie_breaker\"]\n",
    "final_df = completed_matches.select(*columns_to_keep)\n",
    "print(\"Final DataFrame schema:\")\n",
    "final_df.printSchema()\n",
    "print(\"\\nSample data from final DataFrame:\")\n",
    "final_df.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "level 16 task 4.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}