{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Processing Results ===\n",
      "\n",
      "Processing complete. Check 'data_processing.log' for detailed logs.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import logging\n",
    "import pandas as pd\n",
    "from queue import Queue\n",
    "import time\n",
    "from typing import List, Dict\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(threadName)s - %(levelname)s - %(message)s',\n",
    "    filename='data_processing.log',\n",
    "    filemode='w'\n",
    ")\n",
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self.results_queue = Queue()\n",
    "        self.processed_data = {}\n",
    "    def process_dataset(self, file_path: str):\n",
    "        \"\"\"Process a single CSV file and compute basic statistics\"\"\"\n",
    "        try:\n",
    "            thread_name = threading.current_thread().name\n",
    "            logging.info(f\"{thread_name}: Starting processing {file_path}\")\n",
    "            start_time = time.time()\n",
    "            df = pd.read_csv(file_path)\n",
    "            dataset_name = file_path.split('/')[-1].split('.')[0]\n",
    "            numeric_stats = {}\n",
    "            for column in df.select_dtypes(include=['number']).columns:\n",
    "                numeric_stats[column] = {\n",
    "                    'mean': df[column].mean(),\n",
    "                    'max': df[column].max(),\n",
    "                    'min': df[column].min(),\n",
    "                    'median': df[column].median(),\n",
    "                    'std': df[column].std()\n",
    "                }\n",
    "            result = {\n",
    "                'dataset': dataset_name,\n",
    "                'file_path': file_path,\n",
    "                'stats': numeric_stats,\n",
    "                'processing_time': time.time() - start_time,\n",
    "                'rows_processed': len(df)\n",
    "            }\n",
    "            self.results_queue.put(result)\n",
    "            logging.info(f\"{thread_name}: Finished processing {file_path}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"{thread_name}: Error processing {file_path} - {str(e)}\")\n",
    "            self.results_queue.put({\n",
    "                'dataset': file_path,\n",
    "                'error': str(e)\n",
    "            })\n",
    "    def process_all_datasets(self, file_paths: List[str]):\n",
    "        \"\"\"Process multiple datasets in parallel using threads\"\"\"\n",
    "        threads = []\n",
    "        for file_path in file_paths:\n",
    "            thread = threading.Thread(\n",
    "                target=self.process_dataset,\n",
    "                args=(file_path,),\n",
    "                name=f\"Processor-{file_path.split('/')[-1]}\"\n",
    "            )\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "            time.sleep(0.1)\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "        while not self.results_queue.empty():\n",
    "            result = self.results_queue.get()\n",
    "            if 'error' not in result:\n",
    "                self.processed_data[result['dataset']] = result\n",
    "            else:\n",
    "                logging.warning(f\"Failed to process {result['dataset']}: {result['error']}\")\n",
    "    def display_results(self):\n",
    "        \"\"\"Display the processing results\"\"\"\n",
    "        print(\"\\n=== Data Processing Results ===\")\n",
    "        for dataset, result in self.processed_data.items():\n",
    "            print(f\"\\nDataset: {dataset}\")\n",
    "            print(f\"File: {result['file_path']}\")\n",
    "            print(f\"Rows processed: {result['rows_processed']}\")\n",
    "            print(f\"Processing time: {result['processing_time']:.2f} seconds\")            \n",
    "            if result['stats']:\n",
    "                print(\"\\nStatistics:\")\n",
    "                for column, stats in result['stats'].items():\n",
    "                    print(f\"\\nColumn: {column}\")\n",
    "                    print(f\"  Mean: {stats['mean']:.2f}\")\n",
    "                    print(f\"  Max: {stats['max']:.2f}\")\n",
    "                    print(f\"  Min: {stats['min']:.2f}\")\n",
    "                    print(f\"  Median: {stats['median']:.2f}\")\n",
    "                    print(f\"  Std Dev: {stats['std']:.2f}\")\n",
    "            else:\n",
    "                print(\"No numeric columns found for statistics\")\n",
    "\n",
    "def main():\n",
    "    files_to_process = [\n",
    "        'data/house_prices.csv',\n",
    "        'data/sales_data.csv'\n",
    "    ]\n",
    "    processor = DataProcessor()\n",
    "    processor.process_all_datasets(files_to_process)\n",
    "    processor.display_results()   \n",
    "    print(\"\\nProcessing complete. Check 'data_processing.log' for detailed logs.\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
